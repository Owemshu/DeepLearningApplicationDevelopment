{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers, optimizers, Sequential\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "batches = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 17:13:29.568621: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-11-17 17:13:29.568755: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-11-17 17:13:29.635184: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "batch: (128, 28, 28) (128,)\n"
     ]
    }
   ],
   "source": [
    "def preprocess(x, y):\n",
    "    # 并做归一化处理\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "(x, y), (x_test, y_test) = fashion_mnist.load_data()\n",
    "db = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "db = db.map(preprocess).shuffle(10000).batch(batches)\n",
    "\n",
    "db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "db_test = db_test.map(preprocess).batch(batches)\n",
    "\n",
    "db_iter = iter(db)\n",
    "sample = next(db_iter)\n",
    "print('batch:', sample[0].shape, sample[1].shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               200960    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 244,522\n",
      "Trainable params: 244,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    layers.Dense(256, activation=tf.nn.relu),\n",
    "    # [b,256]--> [b,128]\n",
    "    layers.Dense(128, activation=tf.nn.relu),\n",
    "    # [b, 128] --> [b,64]\n",
    "    layers.Dense(64, activation=tf.nn.relu),\n",
    "    # [b,64] --> [b,32]\n",
    "    layers.Dense(32, activation=tf.nn.relu),\n",
    "    # [b,32] --> [b,10] 输出层\n",
    "    layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.build(input_shape=[None, 28 * 28])\n",
    "optimizers = optimizers.Adam(learning_rate=1e-3)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------epoch 1---------------------\n",
      "step:100, loss:0.50941\n",
      "step:200, loss:0.56438\n",
      "step:300, loss:0.47671\n",
      "step:400, loss:0.52274\n",
      "train acc:0.85217\n",
      "text acc:0.83680\n",
      "---------------------epoch 2---------------------\n",
      "step:100, loss:0.33205\n",
      "step:200, loss:0.33108\n",
      "step:300, loss:0.36324\n",
      "step:400, loss:0.30593\n",
      "train acc:0.88115\n",
      "text acc:0.86330\n",
      "---------------------epoch 3---------------------\n",
      "step:100, loss:0.26997\n",
      "step:200, loss:0.46384\n",
      "step:300, loss:0.35244\n",
      "step:400, loss:0.27779\n",
      "train acc:0.88388\n",
      "text acc:0.86650\n",
      "---------------------epoch 4---------------------\n",
      "step:100, loss:0.26404\n",
      "step:200, loss:0.36499\n",
      "step:300, loss:0.38806\n",
      "step:400, loss:0.23430\n",
      "train acc:0.89573\n",
      "text acc:0.87530\n",
      "---------------------epoch 5---------------------\n",
      "step:100, loss:0.43204\n",
      "step:200, loss:0.33360\n",
      "step:300, loss:0.26441\n",
      "step:400, loss:0.29038\n",
      "text acc:0.87470\n"
     ]
    }
   ],
   "source": [
    "acc_test = 0\n",
    "for epoch in range(5):\n",
    "    print(\"---------------------epoch{:2d}---------------------\".format(epoch+1))\n",
    "    for step, (x, y) in enumerate(db):\n",
    "        x = tf.reshape(x, [-1, 28 * 28])\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x)\n",
    "            y_onehot = tf.one_hot(y, depth=10)\n",
    "            loss_mse = tf.reduce_mean(tf.losses.MSE(y_onehot, logits))\n",
    "            loss_ce = tf.losses.categorical_crossentropy(y_onehot, logits, from_logits=True)\n",
    "            loss_ce = tf.reduce_mean(loss_ce)\n",
    "\n",
    "        grads = tape.gradient(loss_ce, model.trainable_variables)\n",
    "        optimizers.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if (step+1) % 100 == 0:\n",
    "            print('step:{:3d}, loss:{:.5f}'.format(step+1, float(loss_ce), float(loss_mse)))\n",
    "\n",
    "    total_correct = 0\n",
    "    total_num = 0\n",
    "    for x, y in db_test:\n",
    "        x = tf.reshape(x, [-1, 28 * 28])\n",
    "        logits = model(x)\n",
    "\n",
    "        prob = tf.nn.softmax(logits, axis=1)\n",
    "        pred = tf.argmax(prob, axis=1)\n",
    "        pred = tf.cast(pred, dtype=tf.int32)\n",
    "        correct = tf.equal(pred, y)\n",
    "        correct = tf.reduce_sum(tf.cast(correct, dtype=tf.int32))\n",
    "        total_correct += int(correct)\n",
    "        total_num += x.shape[0]\n",
    "    acc = total_correct / total_num\n",
    "    if acc > acc_test:\n",
    "        acc_test = acc\n",
    "        total_correct = 0\n",
    "        total_num = 0\n",
    "        for x, y in db:\n",
    "            x = tf.reshape(x, [-1, 28 * 28])\n",
    "            logits = model(x)\n",
    "\n",
    "            prob = tf.nn.softmax(logits, axis=1)\n",
    "            pred = tf.argmax(prob, axis=1)\n",
    "            pred = tf.cast(pred, dtype=tf.int32)\n",
    "            correct = tf.equal(pred, y)\n",
    "            correct = tf.reduce_sum(tf.cast(correct, dtype=tf.int32))\n",
    "            total_correct += int(correct)\n",
    "            total_num += x.shape[0]\n",
    "        acc_train = total_correct / total_num\n",
    "        print('train acc:{:.5f}'.format(acc_train))\n",
    "    print('text acc:{:.5f}'.format(acc))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
